{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Ingest\n",
    "======\n",
    "\n",
    "The data is a key component of any machine learning algorithm.\n",
    "The ingest of the data,\n",
    "including the cleanup and labelling stages,\n",
    "is often the most time consuming.\n",
    "It requires taking the raw data,\n",
    "in our case Molecular Dyanmics trajectories, and\n",
    "computing or extracting the quantities which will be used\n",
    "for the Machine Learning.\n",
    "\n",
    "In this example we will be using the relative orientations\n",
    "of neighbouring molecules for our classification.\n",
    "So by the end of this workbook we will have\n",
    "a collection of data containing;\n",
    "\n",
    "- the relative orientations of up to 6 nearest neighbours,\n",
    "- the known classification, and\n",
    "- temperature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input files\n",
    "--------------\n",
    "\n",
    "The input data for this tutorial is in the folder `data`,\n",
    "which contains a series of `.gsd` files.\n",
    "This is the default file format of [Hoomd-blue](http://glotzerlab.engin.umich.edu/hoomd-blue/)\n",
    "a molecular dynamics package designed to run on GPUs\n",
    "from the Glotzer group at the University of Michigan.\n",
    "\n",
    "To read these files we are going to use the [gsd](http://gsd.readthedocs.io/en/latest/) package\n",
    "that the glotzer group provide.\n",
    "To read files from other simulation packages [MDAnalysis](https://www.mdanalysis.org/)\n",
    "is a python package that will read nearly any file type.\n",
    "To read all the files that we want,\n",
    "we are going to use the [pathlib](https://docs.python.org/3/library/pathlib.html) module \n",
    "from python's (>= 3.4) standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import gsd.hoomd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Path object pointing to the directory holding\n",
    "# all the input files we will be using\n",
    "directory = Path('../data/simulations/melting')\n",
    "# Search for all files in the above directory which end in .gsd\n",
    "input_files = directory.glob('*.gsd')\n",
    "\n",
    "# input files is a generator, essentially a list of files,\n",
    "# so we can iterate through each individually\n",
    "for fname in input_files:\n",
    "    # This is a context manager. We open the file and assign\n",
    "    # it to the variable traj.\n",
    "    with gsd.hoomd.open(str(fname)) as trj:\n",
    "        # This extracts the first (and only) frame of the trajectory\n",
    "        snap = trj[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on context managers in Python,\n",
    "Jeff Knupp has a [good explanation](https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate Simulation Data\n",
    "\n",
    "This code is enough to read all the input files,\n",
    "so the next step is to actually do something useful\n",
    "with each of the files.\n",
    "\n",
    "Within each of the filenames I have included \n",
    "the parameters of the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling Data\n",
    "\n",
    "This has given us sufficient information about the simulation,\n",
    "we now need to work out the classification of each molecule.\n",
    "The configurations that I have prepared consist of two phases,\n",
    "the middle 2/3 in the $x$ and $y$ directions is crystalline\n",
    "while the remainer of the simulation cell is liquid.\n",
    "This is probably easiest to understand using a picture;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"2a07a75b-1880-44d1-b0dc-46b10c0538d9\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"2a07a75b-1880-44d1-b0dc-46b10c0538d9\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"2a07a75b-1880-44d1-b0dc-46b10c0538d9\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '2a07a75b-1880-44d1-b0dc-46b10c0538d9' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.16.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"2a07a75b-1880-44d1-b0dc-46b10c0538d9\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"2a07a75b-1880-44d1-b0dc-46b10c0538d9\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"2a07a75b-1880-44d1-b0dc-46b10c0538d9\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '2a07a75b-1880-44d1-b0dc-46b10c0538d9' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.16.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"2a07a75b-1880-44d1-b0dc-46b10c0538d9\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Snapshot' object has no attribute 'orientation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a5f18eb0fbdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/crystal/lib/python3.6/site-packages/sdanalysis/figures/configuration.py\u001b[0m in \u001b[0;36mplot_frame\u001b[0;34m(frame, order_function, order_list, source, molecule)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;34m\"\"\"Plot snapshot using bokeh.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     data = frame2data(\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolecule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmolecule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m     plot = figure(\n",
      "\u001b[0;32m~/.pyenv/versions/crystal/lib/python3.6/site-packages/sdanalysis/figures/configuration.py\u001b[0m in \u001b[0;36mframe2data\u001b[0;34m(frame, order_function, order_list, molecule)\u001b[0m\n\u001b[1;32m     80\u001b[0m ) -> Dict[str, Any]:\n\u001b[1;32m     81\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mMolecule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquaternion2z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Colour all particles with the darker shade\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mcolour\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolour_orientation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Snapshot' object has no attribute 'orientation'"
     ]
    }
   ],
   "source": [
    "from sdanalysis.figures.configuration import plot_frame\n",
    "from sdanalysis.util import get_filename_vars\n",
    "from bokeh.plotting import show, output_notebook\n",
    "output_notebook()\n",
    "\n",
    "show(plot_frame(snap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define molecules that have an $x$ position in the range\n",
    "$\n",
    "-L_x/3 < x < L_x/3\n",
    "$\n",
    "and have a $y$ position in the range\n",
    "$\n",
    "-L_y/3 < y < L_y/3\n",
    "$\n",
    "as being crystalline, with the crystal structure taken from the filename. \n",
    "The remaining molecules can be classed as the generic liquid.\n",
    "As before we can write a simple function\n",
    "that takes a snapshot and the cyrstal structure,\n",
    "returning the annotated classification of all molecules in the simulation.\n",
    "At the interface of the two phases\n",
    "the classification is not well defined,\n",
    "so for the purposes of training and testing, \n",
    "I am going to remove molecules within a distance of 3.5,\n",
    "a bit over 1 neighbour shell,\n",
    "to the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classify_mols(snapshot, crystal, boundary_buffer=3.5):\n",
    "    \"\"\"Classify molecules as crystalline, amorphous or boundary.\"\"\"\n",
    "    # This is the method of extracting the positions from a gsd snapshot\n",
    "    position = snapshot.particles.position\n",
    "    # This gets the details of the box from the simulation\n",
    "    box = snapshot.configuration.box\n",
    "    \n",
    "    # All axes have to be True, True == 1, use product for logical and operation\n",
    "    is_crystal = np.product(np.abs(position) < box[:3]/3, axis=1).astype(bool)\n",
    "    boundary = np.logical_and(np.product(np.abs(position) < box[:3]/3+boundary_buffer, axis=1),\n",
    "                              np.product(np.abs(position) > box[:3]/3-boundary_buffer, axis=1))\n",
    "    \n",
    "    # Create classification array\n",
    "    classification = np.full(snapshot.particles.N, 'liq', dtype='<U4')\n",
    "    classification[is_crystal] = crystal\n",
    "    classification[boundary] = None\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute training features\n",
    "\n",
    "The final step is to compute the nearest neighbours for each of the molecules.\n",
    "Most of the work of this function is done\n",
    "using a function I wrote, `relative_orientations`.\n",
    "This function uses the the kdtree algorithm from scipy to compute the neighbours efficiently.\n",
    "A side effect of using this function is that the neighbours are returned in order of increasing distance.\n",
    "Then computes the relative orientation of the neighbour orientations using quaternion maths.\n",
    "\n",
    "It should be noted that this the relative orientations function requires the orientations\n",
    "to be expressed as quaternions. \n",
    "\n",
    "The parameters to the relative_orientations function, `max_radius` and `max_neighbours`\n",
    "are passed to the algorithm computing the neighbour lists.\n",
    "`max_radius` defines the maximum distance to search for neighbours,\n",
    "beyond this distance molecules are not considered neighbours.\n",
    "The `max_neighbours` parameter defines the maximum number of neighbours to find.\n",
    "Where there are more molecules within the `max_radius` \n",
    "only the closest `max_neighbours` are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdanalysis.order import relative_orientations\n",
    "\n",
    "def compute_orientations(snapshot):\n",
    "    \"\"\"Compute the orientation of 6 nearest neighbours from a gsd snapshot.\"\"\"\n",
    "    # I am assuming an orthorhombic simulation cell\n",
    "    box = snapshot.configuration.box[:3]\n",
    "    return relative_orientations(box=box,\n",
    "                                 position=snapshot.particles.position,\n",
    "                                 orientation=snapshot.particles.orientation,\n",
    "                                 max_radius=3.5,\n",
    "                                 max_neighbours=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our function works \n",
    "compute_orientations(snap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Data\n",
    "----------------\n",
    "\n",
    "Now with all the parts in place we can load all the data into a pandas DataFrame.\n",
    "Taking the code we had at the start to read in all the snapshots,\n",
    "we can now apply the functions we have just written,\n",
    "\n",
    "- `get_sim_params`,\n",
    "- `classify_mols`, and\n",
    "- `compute_orientations`\n",
    "\n",
    "to process the data into a succinct and usable form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "input_files = directory.glob('*.gsd')\n",
    "all_dataframes = []\n",
    "\n",
    "for fname in input_files:\n",
    "    with gsd.hoomd.open(str(fname)) as trj:\n",
    "        snap = trj[0]\n",
    "        # Get simulation parameters\n",
    "        params = get_filename_vars(fname)\n",
    "        # Classify all molecules\n",
    "        classes = classify_mols(snap, params.crystal)\n",
    "        # Compute the orientations\n",
    "        orientations = compute_orientations(snap)\n",
    "        \n",
    "        # Create dataframe\n",
    "        df = pandas.DataFrame({\n",
    "            'temperature': params.temperature,\n",
    "            'pressure': params.pressure,\n",
    "            'crystal': params.crystal,\n",
    "            'class': classes,\n",
    "            'orient0': orientations[:, 0],\n",
    "            'orient1': orientations[:, 1],\n",
    "            'orient2': orientations[:, 2],\n",
    "            'orient3': orientations[:, 3],\n",
    "            'orient4': orientations[:, 4],\n",
    "            'orient5': orientations[:, 5],\n",
    "        })\n",
    "        \n",
    "        # Remove molecules close to interface\n",
    "        df = df[df['class'] != 'None']\n",
    "        \n",
    "        all_dataframes.append(df)\n",
    "\n",
    "# Collate list of dataframes into single large dataframe\n",
    "training_dataset = pandas.concat(all_dataframes)\n",
    "\n",
    "# Save dataset to file\n",
    "training_dataset.to_hdf('.../data/analysis/training_data.h5', key='trimer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataframe contains reasonable data\n",
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding a Machine Learning Model\n",
    "=================\n",
    "\n",
    "There are many different types of models we can use for classification,\n",
    "each of these models have types of problems they are well suited to.\n",
    "The goal of this notebook is to identify algorithms \n",
    "that will effectively classify our dataset\n",
    "which we can then investigate further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collating the models\n",
    "\n",
    "The first step here is creating a list of models we would like to test.\n",
    "An excellent property of scikit-learn is \n",
    "that all the algorithms have the same API,\n",
    "allowing us to treat them all in the same way. \n",
    "\n",
    "This is not an exhastive list of all the possible classifiers in scikit-learn,\n",
    "just a smattering for comparison.\n",
    "For a more exhastive list check out [the scikit-learn documentation](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning),\n",
    "and feel free to add more to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "ml_models = {\n",
    "    'LR': LogisticRegression(),\n",
    "    'SGD': SGDClassifier(tol=1e-3, max_iter=1000),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'NB': GaussianNB(),\n",
    "    'SVM': SVC(),\n",
    "    'NN': MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training data\n",
    "\n",
    "We need to load in the training dataset we created in the first notebook.\n",
    "At this point we are interested in two sets of data,\n",
    "\n",
    "- $X$, the input data which is the orientation of the six nearest neighbours\n",
    "- $Y$, the true labelled classification of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "training_dataset = pandas.read_hdf('../data/analysis/training_data.h5', key='trimer')\n",
    "X = training_dataset[['orient0', 'orient1', 'orient2', 'orient3', 'orient4', 'orient5']].values\n",
    "Y = training_dataset['class'].values\n",
    "classes = training_dataset['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Models\n",
    "\n",
    "With a collection of models to test,\n",
    "we now need some method of testing the models to compare them.\n",
    "To perform the initial screening of datasets\n",
    "we are going to break our training data into two groups,\n",
    "\n",
    "- the training set, comprising 80% of the molecules\n",
    "- the validation set, comprising the remaining 20%.\n",
    "\n",
    "This division of the dataset gives us a set of data \n",
    "previously unseen by the algorithms,\n",
    "giving us a method of testing whether\n",
    "the algorithm is acutally learning the underlying features,\n",
    "or just 'memorising' the training data.\n",
    "This division of data will be through a random selection\n",
    "so as not to bias the selection of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "\n",
    "selected = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "X_train, X_validation, Y_train, Y_validation = selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of the models which\n",
    "warrant a further investigation,\n",
    "we can iterate through each of our models.\n",
    "Each model is scored by breaking the training data into `n_splits`,\n",
    "using one of these splits for testing and\n",
    "the remaining splits for training.\n",
    "This process is referred to as *cross validation*\n",
    "and typically the number of splits is 10.\n",
    "For the purposes of this running in a reasonable amount of time,\n",
    "`n_splits` is set to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring='accuracy'\n",
    "n_splits = 2\n",
    "# Typically n_splits would be 10 but it runs much slower\n",
    "#n_splits = 10\n",
    "\n",
    "# Iterate through each model in our dictionary of models\n",
    "for name, model in ml_models.items():\n",
    "    kfold = model_selection.KFold(n_splits=n_splits, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    print(f'{name:5s}: {cv_results.mean():.5f} Â± {cv_results.std():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all the algorithms tested, \n",
    "there are three that stand out \n",
    "\n",
    "- K-Nearest Neighbours (KNN),\n",
    "- Support Vector Machine (SVM), and\n",
    "- Neural Network (NN)\n",
    "\n",
    "with accuracies in excess of 95%. \n",
    "\n",
    "So with these three algorithms it is likely worth\n",
    "tweaking the algorithms slightly from \n",
    "the defualt paramters in an effort to improve performance.\n",
    "It is also worth understanding which classes\n",
    "each of these algorithms is strongest at classifying.\n",
    "For this additional data we are going to be using a [confusion matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).\n",
    "In a confusion matrix, \n",
    "the diagonal elements represent the correct classifications,\n",
    "while the off diagonal elements are the values \n",
    "which were incorrectly classified.\n",
    "\n",
    "Below we have a handy function from the scikit-learn documentation\n",
    "that will nicely plot the confusion matrix as a heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is this point where our breaking the data into\n",
    "training and validation sets becomes useful.\n",
    "We can train a classifier using the training set,\n",
    "then generate predictions of the validation dataset\n",
    "using the known values of the validation data\n",
    "to generate the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = ml_models['KNN']\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "plot_confusion_matrix(confusion_matrix(Y_validation, predictions, labels=classes), classes, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = ml_models['SVM']\n",
    "svm.fit(X_train, Y_train)\n",
    "predictions = svm.predict(X_validation)\n",
    "plot_confusion_matrix(confusion_matrix(Y_validation, predictions, labels=classes), classes, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ml_models['NN']\n",
    "nn.fit(X_train, Y_train)\n",
    "predictions = nn.predict(X_validation)\n",
    "plot_confusion_matrix(confusion_matrix(Y_validation, predictions, labels=classes), classes, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that all of the models\n",
    "have the most difficulty with the liquid/crystal characterisation,\n",
    "with the largest proportion of false positives being \n",
    "crystal incorrectly classified as liquid. \n",
    "To make this model we have created persistent\n",
    "it needs to be saved which is done using `joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(ml_models['KNN'], '../data/analysis/knn-model.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML in Production\n",
    "=========\n",
    "\n",
    "So far we have been looking at building a machine learning model,\n",
    "while this is nice we actually want to be able to use it\n",
    "to perform useful science.\n",
    "\n",
    "This notebook will demonstrate the application of the machine learning algorithm\n",
    "that we built in the first part of the tutorial to\n",
    "the classification of a previously unseen configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Model\n",
    "----------------\n",
    "\n",
    "At the end of the [previous notebook](02_Lets_Find_A_Model.ipynb)\n",
    "we saved the model as a python pickle using scikit-learn's `joblib` library.\n",
    "This converted the in memory object that represented the trained state\n",
    "of the machine learning algorithm into a form that could be saved to disk.\n",
    "By reading the file `knn-model.pkl` from disk,\n",
    "we can load the trained K-Nearest Neighbours model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "model = joblib.load('data/knn-model.pkl')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model now loaded we need some data to apply it to.\n",
    "For this we need to load a configuration and\n",
    "compute the relative orientation of all the neareset neighbours.\n",
    "With the nearest neighbour orientations comptued,\n",
    "all that is left to do is use the model to predict the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdanalysis.order import relative_orientations\n",
    "\n",
    "with gsd.hoomd.open('data/unknown/configuration.gsd') as trj:\n",
    "    snap = trj[0]\n",
    "orientations = relative_orientations(snap.configuration.box,\n",
    "                           snap.particles.position,\n",
    "                           snap.particles.orientation,\n",
    "                           max_neighbours=6,\n",
    "                           max_radius=3.5)\n",
    "classes = model.predict(orientations)\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the classification in hand we can perform any number of analyses.\n",
    "Below I am taking the classes array and using pandas\n",
    "to generate a histogram of the data.\n",
    "We can see that most of the configuration is liquid,\n",
    "there are large amounts of both the p2 and p2gg crystals, and \n",
    "a small number of pg crystals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "%matplotlib inline\n",
    "\n",
    "pandas.Series(classes).value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want a better understanding of the configuration,\n",
    "we can plot the configuration in the notebook,\n",
    "colouring by the classification.\n",
    "For this I am using [bokeh](https://bokeh.pydata.org/en/latest/)\n",
    "since it allows interacting with the dataset by panning a zooming,\n",
    "allowing for both an overview and investigation in a single figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bokeh.plotting import show, output_notebook, figure\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.palettes import Colorblind4 as palette\n",
    "from sdanalysis.figures.configuration import plot_circles, snapshot2data\n",
    "\n",
    "# Output the final figure to the jupyter notebook\n",
    "output_notebook()\n",
    "\n",
    "# The colours we will assign each class\n",
    "class_colours = {\n",
    "    'liq': palette[0],\n",
    "    'p2': palette[1],\n",
    "    'p2gg': palette[2],\n",
    "    'pg': palette[3],\n",
    "}\n",
    "\n",
    "# Convert the class strings to a colour for plotting\n",
    "coloured_classes = [class_colours[c] for c in classes]\n",
    "\n",
    "# Convert the snapshot to format ready for plotting \n",
    "data = snapshot2data(snap) \n",
    "data['colour'] = np.tile(coloured_classes, 3)\n",
    "data['label'] = np.tile(classes, 3)\n",
    "source = ColumnDataSource(data)\n",
    "\n",
    "# Create the figure\n",
    "p = figure(aspect_scale=1, match_aspect=True, width=920, height=800, active_scroll='wheel_zoom')\n",
    "p.circle('x', 'y', radius='radius', source=source, color='colour', legend='label')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal",
   "language": "python",
   "name": "crystal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
